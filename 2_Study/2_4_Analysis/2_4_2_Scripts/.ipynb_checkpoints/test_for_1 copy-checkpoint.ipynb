{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]\n",
      "MNE version is 0.23.3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import mne\n",
    "from mne.event import define_target_events\n",
    "from mne.channels import make_1020_channel_selections\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs, corrmap)\n",
    "import sklearn\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "\n",
    "print(\"Python version is\", sys.version)\n",
    "print(\"MNE version is\", mne.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]\n",
      "MNE version is 0.23.3\n",
      "                            Anova\n",
      "==============================================================\n",
      "                                  F Value Num DF Den DF Pr > F\n",
      "--------------------------------------------------------------\n",
      "coherency                             nan 1.0000 0.0000    nan\n",
      "prioritization                        nan 1.0000 0.0000    nan\n",
      "stimulus                              nan 1.0000 0.0000    nan\n",
      "coherency:prioritization              nan 1.0000 0.0000    nan\n",
      "coherency:stimulus                    nan 1.0000 0.0000    nan\n",
      "prioritization:stimulus               nan 1.0000 0.0000    nan\n",
      "coherency:prioritization:stimulus  0.0000 1.0000 0.0000    nan\n",
      "==============================================================\n",
      "\n",
      "                            Anova\n",
      "==============================================================\n",
      "                                  F Value Num DF Den DF Pr > F\n",
      "--------------------------------------------------------------\n",
      "coherency                             nan 1.0000 0.0000    nan\n",
      "prioritization                        nan 1.0000 0.0000    nan\n",
      "stimulus                              nan 1.0000 0.0000    nan\n",
      "coherency:prioritization              nan 1.0000 0.0000    nan\n",
      "coherency:stimulus                    nan 1.0000 0.0000    nan\n",
      "prioritization:stimulus               nan 1.0000 0.0000    nan\n",
      "coherency:prioritization:stimulus  0.0000 1.0000 0.0000    nan\n",
      "==============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuyikang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\stats\\anova.py:601: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mse = (ssr1 - ssr) / df2\n",
      "C:\\Users\\liuyikang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\statsmodels\\stats\\anova.py:594: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  mse = ssr / df_resid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Python version is\", sys.version)\n",
    "print(\"MNE version is\", mne.__version__)\n",
    "\n",
    "## read data\n",
    "#subj_idx\n",
    "subjects = [ #\n",
    "                 'sub-014', #\n",
    "                 ]\n",
    "# task\n",
    "tasks=[]\n",
    "for side in ['outside','inside']:\n",
    "    task='sourcedata-eeg_'+side+'-MRT'\n",
    "    tasks.append(task)\n",
    "# runs\n",
    "runs=[]\n",
    "for task in tasks:\n",
    "    if task == tasks[0]:\n",
    "        side = 'outside'\n",
    "        for i in range(1,3):\n",
    "            run = side+'MRT_run-0'+str(i)+'_beh.tsv'\n",
    "            runs.append(run)\n",
    "    else:\n",
    "        side='inside'\n",
    "        for i in range(1,6):\n",
    "            run = side+'MRT_run-0'+str(i)+'_beh.tsv'\n",
    "            runs.append(run)\n",
    "\n",
    "# df_dirs: path + subj_idx + task + datatype + run\n",
    "df_dirs=[]\n",
    "temp_dir =os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))))\n",
    "BIDS_data=\"2_Data\\\\Ostwald2018\\\\BIDS_data\"\n",
    "datatype='beh'\n",
    "for subj_idx in subjects :\n",
    "    for task in tasks:\n",
    "        if task==tasks[0]:\n",
    "            for run_index in range(0,2):\n",
    "                run=runs[run_index]\n",
    "                run=subj_idx+'_task-pdm_acq-'+run\n",
    "                df_dir=os.path.join(temp_dir,BIDS_data,subj_idx,task,datatype,run)\n",
    "                df_dirs.append(df_dir)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "dfs=pd.DataFrame()\n",
    "for df_dir in df_dirs:\n",
    "    if os.path.exists(df_dir):\n",
    "        df=pd.read_csv(df_dir,sep='\\t')\n",
    "        subject=''.join(re.findall(r'BIDS_data\\\\(.+?)\\\\sourcedata',df_dir))\n",
    "        side=''.join(re.findall(r'\\\\sourcedata-eeg_(.+?)-MRT\\\\beh\\\\',df_dir))\n",
    "        run=''.join(re.findall(r'run-0(.+?)_beh',df_dir))\n",
    "        df['subject']=subject\n",
    "        df['side']=side\n",
    "        df['run']=int(run)\n",
    "        dfs=pd.concat([df,dfs])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "## clean data\n",
    "dfs['attention'] = dfs['prioritization_cue'].map({74:'left',75:'right',76:'double'},na_action=None)\n",
    "dfs['coherency']=dfs['condition'].map({1:'high',2:'high',3:'low',4:'low'})\n",
    "dfs['prioritization']=dfs['condition'].map({1:'yes',2:'no',3:'yes',4:'no'})\n",
    "\n",
    "car_images=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54]\n",
    "face_images=[19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72]\n",
    "dfs['category']=dfs['image_index'].isin(car_images).astype(int).map({1:'car', 0:'face'})\n",
    "\n",
    "bedata = dfs.loc[:,['response_time','response_corr','subject','attention','coherency','prioritization','category','run']]\n",
    "bedata.rename(columns={'response_time':'rt','response_corr':'response','subject':'subj_idx','category':'stimulus'},inplace = True)\n",
    "bedata.loc[(bedata['response']==1)&(bedata['stimulus']=='face'),'_response'] = 0 #face\n",
    "bedata.loc[(bedata['response']==1)&(bedata['stimulus']=='car'),'_response'] = 1 #car\n",
    "bedata.loc[(bedata['response']==0)&(bedata['stimulus']=='face'),'_response'] = 0\n",
    "bedata.loc[(bedata['response']==0)&(bedata['stimulus']=='car'),'_response'] = 1\n",
    "bedata['id']=bedata.index\n",
    "bedata = bedata.sort_values(by=['run','id'], axis=0, ascending=True)\n",
    "\n",
    "\n",
    "# cpp\n",
    "#bedata['cpp_peak'] = np.nan\n",
    "#bedata['cpp_slope'] = np.nan\n",
    "#bedata['cpp_amplitude'] = np.nan\n",
    "\n",
    "# ANOVA\n",
    "model_aovrm2way = AnovaRM(bedata,\n",
    "                   'response',\n",
    "                   'subj_idx',\n",
    "                   within=['coherency','prioritization','stimulus'],\n",
    "                   aggregate_func='mean')\n",
    "res2way=model_aovrm2way.fit()\n",
    "print(res2way)\n",
    "model_aovrm2way = AnovaRM(bedata,\n",
    "                   'rt',\n",
    "                   'subj_idx',\n",
    "                   within=['coherency','prioritization','stimulus'],\n",
    "                   aggregate_func='mean')\n",
    "res2way=model_aovrm2way.fit()\n",
    "print(res2way)\n",
    "\n",
    "#event\n",
    "event_dict = {\n",
    "  'Response/car': 5,\n",
    "  'Response/face': 6,\n",
    "  'Stimulus/hc/p/left': 10,\n",
    "  'Stimulus/hc/p/right': 11,\n",
    "  'Stimulus/hc/np/left': 20,\n",
    "  'Stimulus/hc/np/right': 21,\n",
    "  'Stimulus/lc/p/left': 30,\n",
    "  'Stimulus/lc/p/right': 31,\n",
    "  'Stimulus/lc/np/left': 40,\n",
    "  'Stimulus/lc/np/right': 41,\n",
    "  'Cue/Left': 74,\n",
    "  'Cue/Right': 75,\n",
    "  'Cue/double': 76\n",
    "}\n",
    "\n",
    "cue_dict =  {\n",
    "  'Cue/Left': 74,\n",
    "  'Cue/Right': 75,\n",
    "  'Cue/double': 76\n",
    "}\n",
    "\n",
    "stimulus_dict = {\n",
    "  'Stimulus/hc/p/left': 10,\n",
    "  'Stimulus/hc/p/right': 11,\n",
    "  'Stimulus/hc/np/left': 20,\n",
    "  'Stimulus/hc/np/right': 21,\n",
    "  'Stimulus/lc/p/left': 30,\n",
    "  'Stimulus/lc/p/right': 31,\n",
    "  'Stimulus/lc/np/left': 40,\n",
    "  'Stimulus/lc/np/right': 41,\n",
    "}\n",
    "\n",
    "response_dict = {\n",
    "  'Response/car': 5,\n",
    "  'Response/face': 6,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading d:\\yikang1020\\yikangsystem1020\\2_Projects\\202206_Centro-parietal positivity\\2_Study\\2_4_Analysis\\2_4_3_tmp_data\\sub-014.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 62) active\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LIUYIK~1\\AppData\\Local\\Temp/ipykernel_12936/1378522758.py:9: RuntimeWarning: This filename (d:\\yikang1020\\yikangsystem1020\\2_Projects\\202206_Centro-parietal positivity\\2_Study\\2_4_Analysis\\2_4_3_tmp_data\\sub-014.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(edata_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading d:\\yikang1020\\yikangsystem1020\\2_Projects\\202206_Centro-parietal positivity\\2_Study\\2_4_Analysis\\2_4_3_tmp_data\\sub-014_res.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 62) active\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LIUYIK~1\\AppData\\Local\\Temp/ipykernel_12936/1378522758.py:15: RuntimeWarning: This filename (d:\\yikang1020\\yikangsystem1020\\2_Projects\\202206_Centro-parietal positivity\\2_Study\\2_4_Analysis\\2_4_3_tmp_data\\sub-014_res.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs_res = mne.read_epochs(edata_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "284 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "\n",
    "\n",
    "    \n",
    "    tname = os.path.join(subject + \".fif\")\n",
    "    \n",
    "    edata_path = os.path.join(os.path.dirname(os.getcwd()),'2_4_3_tmp_data', tname)\n",
    "    \n",
    "    epochs = mne.read_epochs(edata_path)\n",
    "\n",
    "    tname = os.path.join(subject + \"_res.fif\")\n",
    "    \n",
    "    edata_path = os.path.join(os.path.dirname(os.getcwd()),'2_4_3_tmp_data', tname)\n",
    "    \n",
    "    epochs_res = mne.read_epochs(edata_path)\n",
    "\n",
    "    if subject != 'sub-004':\n",
    "\n",
    "        # epochs_baseline\n",
    "        channel = ['CPz','CP1','CP2']\n",
    "\n",
    "        time = [-0.2, 0]\n",
    "\n",
    "\n",
    "        # cpp peak\n",
    "        time = [-0.25, -0.1]\n",
    "\n",
    "        epochs_CPP = epochs_res.copy().pick_channels(channel)\n",
    "\n",
    "        epochs_CPP = epochs_CPP.crop(time[0],time[1])\n",
    "\n",
    "        times = epochs_CPP.times\n",
    "\n",
    "        epochs_CPP = epochs_CPP.get_data()\n",
    "\n",
    "        epochs_CPP = np.mean(epochs_CPP, axis = 1)\n",
    "\n",
    "        CPP_peak = np.amax(epochs_CPP, axis = 1)\n",
    "\n",
    "        # cpp slope\n",
    "        time = [-0.25, -0.1]\n",
    "\n",
    "        epochs_CPP = epochs_res.copy().pick_channels(channel)\n",
    "\n",
    "        epochs_CPP = epochs_CPP.crop(time[0],time[1])\n",
    "\n",
    "        times = epochs_CPP.times\n",
    "\n",
    "        epochs_CPP = epochs_CPP.get_data()\n",
    "\n",
    "        epochs_CPP = np.mean(epochs_CPP, axis = 1)\n",
    "\n",
    "        CPP_slopes = []\n",
    "        for i in range(epochs_CPP.shape[0]):\n",
    "            CPP_slope = np.polyfit(times,epochs_CPP[i,:],1)[0]\n",
    "            CPP_slopes = np.append(CPP_slopes,CPP_slope)\n",
    "\n",
    "        channel = ['CPz','CP1','CP2']\n",
    "\n",
    "        # cpp amplitude\n",
    "        time = [-0.1, -0]\n",
    "\n",
    "\n",
    "        epochs_CPP = epochs_res.copy().pick_channels(channel)\n",
    "\n",
    "        epochs_CPP = epochs_CPP.crop(time[0],time[1])\n",
    "\n",
    "        times = epochs_CPP.times\n",
    "\n",
    "        epochs_CPP = epochs_CPP.get_data()\n",
    "\n",
    "        epochs_CPP = np.mean(epochs_CPP, axis = 1) \n",
    "\n",
    "        CPP_amplitudes = np.mean(epochs_CPP, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "        # which trial has cpp\n",
    "        consecutives = []\n",
    "\n",
    "        for trial in range(epochs_CPP.shape[0]):\n",
    "            ps = []\n",
    "            for i in range(len(times)):\n",
    "                t,p = ttest_1samp(epochs_CPP[trial,:],0)\n",
    "                if p<=0.05:\n",
    "                    p = 1\n",
    "                else:\n",
    "                    p = 0\n",
    "                ps = np.append(ps,p)\n",
    "            start = 0\n",
    "            end = start + 15\n",
    "            consecutive = False\n",
    "            while (end <= len(times)) and (consecutive == False): \n",
    "                if np.sum(ps[start:end]) == 15:\n",
    "                    consecutive = True\n",
    "                else:\n",
    "                    start = start + 1\n",
    "                    end = start + 15\n",
    "            consecutives = np.append(consecutives,consecutive)\n",
    "\n",
    "        CPP_peak[np.where(consecutives == 0)] = -1\n",
    "        bedata.loc[bedata['subj_idx']==subject,'index'] = np.arange(288)\n",
    "        # cpp in bedata\n",
    "\n",
    "        where = np.array(np.where(bedata.loc[bedata['subj_idx']==subject,'rt'].isnull()))[0]\n",
    "\n",
    "        cpp_df = pd.DataFrame({'id':np.setdiff1d(np.arange(288), where),\n",
    "              'cpp_peak':CPP_peak,\n",
    "              'cpp_slope':CPP_slope,\n",
    "              'cpp_amplitude':CPP_amplitudes,\n",
    "                })\n",
    "\n",
    "        bedata['id'] = range(288)\n",
    "        \n",
    "        bedata = bedata.merge(cpp_df, on ='id', how = 'outer' )\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>response</th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>attention</th>\n",
       "      <th>coherency</th>\n",
       "      <th>prioritization</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>run</th>\n",
       "      <th>_response</th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>cpp_peak</th>\n",
       "      <th>cpp_slope</th>\n",
       "      <th>cpp_amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.866449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>left</td>\n",
       "      <td>high</td>\n",
       "      <td>yes</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.142212e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-4.243285e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.649502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>right</td>\n",
       "      <td>high</td>\n",
       "      <td>yes</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.458391e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-1.235200e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>right</td>\n",
       "      <td>high</td>\n",
       "      <td>yes</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.465091e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>6.119716e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.504805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>double</td>\n",
       "      <td>low</td>\n",
       "      <td>no</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.772622e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>1.310471e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.386772</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>double</td>\n",
       "      <td>low</td>\n",
       "      <td>no</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.319610e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-4.922940e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.896695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>right</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>face</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>1.429810e-07</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>4.880491e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1.774705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>double</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>car</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>4.011082e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-5.420801e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.730411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>double</td>\n",
       "      <td>low</td>\n",
       "      <td>no</td>\n",
       "      <td>face</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "      <td>-5.970941e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-1.270730e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.718854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>left</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>car</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286</td>\n",
       "      <td>286</td>\n",
       "      <td>-2.133835e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-5.622259e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.526024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sub-014</td>\n",
       "      <td>right</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>face</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287</td>\n",
       "      <td>287</td>\n",
       "      <td>4.382188e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>3.594987e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rt  response subj_idx attention coherency prioritization stimulus  \\\n",
       "0    0.866449       1.0  sub-014      left      high            yes      car   \n",
       "1    1.649502       1.0  sub-014     right      high            yes      car   \n",
       "2    0.373234       1.0  sub-014     right      high            yes     face   \n",
       "3    0.504805       1.0  sub-014    double       low             no      car   \n",
       "4    0.386772       1.0  sub-014    double       low             no     face   \n",
       "..        ...       ...      ...       ...       ...            ...      ...   \n",
       "283  0.896695       1.0  sub-014     right       low            yes     face   \n",
       "284  1.774705       1.0  sub-014    double      high             no      car   \n",
       "285  0.730411       1.0  sub-014    double       low             no     face   \n",
       "286  0.718854       1.0  sub-014      left       low            yes      car   \n",
       "287  0.526024       1.0  sub-014     right       low            yes     face   \n",
       "\n",
       "     run  _response   id  index      cpp_peak  cpp_slope  cpp_amplitude  \n",
       "0      1        1.0    0      0  3.142212e-06  -0.000004  -4.243285e-06  \n",
       "1      1        1.0    1      1  1.458391e-06  -0.000004  -1.235200e-06  \n",
       "2      1        0.0    2      2  5.465091e-06  -0.000004   6.119716e-06  \n",
       "3      1        1.0    3      3  5.772622e-06  -0.000004   1.310471e-06  \n",
       "4      1        0.0    4      4  5.319610e-06  -0.000004  -4.922940e-07  \n",
       "..   ...        ...  ...    ...           ...        ...            ...  \n",
       "283    2        0.0  283    283  1.429810e-07  -0.000004   4.880491e-06  \n",
       "284    2        1.0  284    284  4.011082e-06  -0.000004  -5.420801e-06  \n",
       "285    2        0.0  285    285 -5.970941e-06  -0.000004  -1.270730e-06  \n",
       "286    2        1.0  286    286 -2.133835e-06  -0.000004  -5.622259e-06  \n",
       "287    2        0.0  287    287  4.382188e-06  -0.000004   3.594987e-06  \n",
       "\n",
       "[288 rows x 14 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bedata = bedata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedata=bedata.drop(bedata[bedata['cpp_peak']==-1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedata = bedata.dropna(axis=0,how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedata.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  =open(\"test.txt\",mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7698be9997df07547d4a08fe6d7a8ab77df170c0c470ab0ace6a1c514673cd42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
